{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, MinMaxScaler\n",
    "    )\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, accuracy_score\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quake_frame = pd.read_csv('data/consolidated_data.csv')\n",
    "\n",
    "quake_frame['simple_label'] = quake_frame['type'] != 'earthquake'\n",
    "\n",
    "quake_frame.drop(['id', 'Unnamed: 0', 'place', 'time', 'updated', 'type'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling, no imputation\n",
    "\n",
    "Keeping the Random Forest from before, we oversample by throwing away the NA values and test various strategies to see the different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude           0\n",
       "longitude          0\n",
       "depth              0\n",
       "mag                0\n",
       "magType            0\n",
       "nst                0\n",
       "gap                0\n",
       "dmin               0\n",
       "rms                0\n",
       "net                0\n",
       "horizontalError    0\n",
       "depthError         0\n",
       "magError           0\n",
       "magNst             0\n",
       "status             0\n",
       "locationSource     0\n",
       "magSource          0\n",
       "simple_label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quake_frame.dropna(inplace=True)\n",
    "quake_frame.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227408"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quake_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>37.361674</td>\n",
       "      <td>4.841731</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.964167</td>\n",
       "      <td>37.573000</td>\n",
       "      <td>38.817000</td>\n",
       "      <td>62.030667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>-119.557707</td>\n",
       "      <td>10.027502</td>\n",
       "      <td>-179.098</td>\n",
       "      <td>-122.701333</td>\n",
       "      <td>-120.558833</td>\n",
       "      <td>-118.150167</td>\n",
       "      <td>179.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>6.016756</td>\n",
       "      <td>7.922880</td>\n",
       "      <td>-3.882</td>\n",
       "      <td>1.816000</td>\n",
       "      <td>4.413000</td>\n",
       "      <td>7.830000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mag</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>1.258097</td>\n",
       "      <td>0.694405</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>5.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nst</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>17.010182</td>\n",
       "      <td>13.671235</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gap</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>121.032150</td>\n",
       "      <td>65.767724</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>0.078264</td>\n",
       "      <td>0.342578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>0.079990</td>\n",
       "      <td>141.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rms</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>0.097118</td>\n",
       "      <td>0.195847</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>64.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horizontalError</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>0.801039</td>\n",
       "      <td>2.296862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>194.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthError</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>2.773763</td>\n",
       "      <td>6.903563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>725.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magError</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>0.158215</td>\n",
       "      <td>0.132854</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magNst</th>\n",
       "      <td>1227408.0</td>\n",
       "      <td>12.685281</td>\n",
       "      <td>17.846407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>430.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean        std      min         25%  \\\n",
       "latitude         1227408.0   37.361674   4.841731    0.000   35.964167   \n",
       "longitude        1227408.0 -119.557707  10.027502 -179.098 -122.701333   \n",
       "depth            1227408.0    6.016756   7.922880   -3.882    1.816000   \n",
       "mag              1227408.0    1.258097   0.694405   -2.500    0.800000   \n",
       "nst              1227408.0   17.010182  13.671235    0.000    8.000000   \n",
       "gap              1227408.0  121.032150  65.767724    0.000   72.000000   \n",
       "dmin             1227408.0    0.078264   0.342578    0.000    0.017120   \n",
       "rms              1227408.0    0.097118   0.195847    0.000    0.030000   \n",
       "horizontalError  1227408.0    0.801039   2.296862    0.000    0.270000   \n",
       "depthError       1227408.0    2.773763   6.903563    0.000    0.490000   \n",
       "magError         1227408.0    0.158215   0.132854    0.000    0.090000   \n",
       "magNst           1227408.0   12.685281  17.846407    0.000    4.000000   \n",
       "\n",
       "                        50%         75%         max  \n",
       "latitude          37.573000   38.817000   62.030667  \n",
       "longitude       -120.558833 -118.150167  179.661500  \n",
       "depth              4.413000    7.830000  211.000000  \n",
       "mag                1.180000    1.670000    5.840000  \n",
       "nst               13.000000   22.000000  276.000000  \n",
       "gap              105.000000  153.000000  360.000000  \n",
       "dmin               0.037840    0.079990  141.160000  \n",
       "rms                0.060000    0.130000   64.290000  \n",
       "horizontalError    0.410000    0.720000  194.584100  \n",
       "depthError         0.770000    1.460000  725.300000  \n",
       "magError           0.140000    0.200000    6.110000  \n",
       "magNst             8.000000   14.000000  430.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quake_frame.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this changes the proportions slightly, but not too bad. If anything, one might suggest that at least the mild increase in proportion of non-earthquakes offsets the reduced dataset a little.  \n",
    "Okay, so the problematic values are no longer there, that's something.  \n",
    "Let's try this.  \n",
    "We'll start by mixing up the data frame, then encoding all the categories numerically and splitting it sklearn style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quake_frame = quake_frame.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "cat_columns = ['magType', 'net', 'status', 'locationSource', 'magSource']\n",
    "\n",
    "for cat in cat_columns:\n",
    "    quake_frame = pd.concat([quake_frame,\n",
    "                             pd.get_dummies(quake_frame[cat], prefix=cat)],\n",
    "                            axis=1)\n",
    "\n",
    "scale_cols = ['latitude', 'longitude', 'depth', 'mag', 'nst', 'gap', 'dmin', 'rms', 'horizontalError',\n",
    " 'depthError', 'magError', 'magNst']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "quake_frame[scale_cols] = scaler.fit_transform(quake_frame[scale_cols])\n",
    "\n",
    "x_cols = ['latitude', 'longitude', 'depth', 'mag', 'nst', 'gap', 'dmin', 'rms', 'horizontalError', 'depthError',\n",
    " 'magError', 'magNst', 'magType_Mb', 'magType_Md', 'magType_Ml', 'magType_Unknown', 'magType_ma', 'magType_mb',\n",
    " 'magType_mc', 'magType_md', 'magType_me', 'magType_mh', 'magType_ml', 'magType_mlg', 'magType_mlr', 'magType_mw',\n",
    " 'net_av', 'net_ci', 'net_hv', 'net_ismpkansas', 'net_ld', 'net_mb', 'net_nc', 'net_nm', 'net_nn', 'net_pr',\n",
    " 'net_se', 'net_uu', 'net_uw', 'status_automatic', 'status_manual', 'status_reviewed', 'locationSource_av',\n",
    " 'locationSource_ci', 'locationSource_hv', 'locationSource_ismp', 'locationSource_ld', 'locationSource_mb',\n",
    " 'locationSource_nc', 'locationSource_nm', 'locationSource_nn', 'locationSource_pr', 'locationSource_se',\n",
    " 'locationSource_uu', 'locationSource_uw', 'magSource_av', 'magSource_ci', 'magSource_hv', 'magSource_ismp',\n",
    " 'magSource_ld', 'magSource_mb', 'magSource_nc', 'magSource_nm', 'magSource_nn', 'magSource_pr', 'magSource_se',\n",
    " 'magSource_uu', 'magSource_uw']\n",
    "\n",
    "y_col = ['simple_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = int(np.round(len(quake_frame.index) * 0.8))\n",
    "\n",
    "train_X = quake_frame.loc[:train_length, x_cols]\n",
    "train_y = quake_frame.loc[:train_length, y_col]\n",
    "\n",
    "valid_X = quake_frame.loc[train_length:, x_cols]\n",
    "valid_y = quake_frame.loc[train_length:, y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9524906071991274\n",
      "Recall:  0.9022962112514351\n",
      "ROC score:  0.950320305041189\n",
      "F1 score:  0.926714226755498\n",
      "Accuracy score:  0.9949364922886403\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = ros.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try AdaSYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8308323329331733\n",
      "Recall:  0.9535017221584385\n",
      "ROC score:  0.9731799151903473\n",
      "F1 score:  0.8879503902491179\n",
      "Accuracy score:  0.991461695765881\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = ada.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import (\n",
    "    SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC, KMeansSMOTE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8547220500103327\n",
      "Recall:  0.9497129735935707\n",
      "ROC score:  0.9718873857206446\n",
      "F1 score:  0.8997172068740483\n",
      "Accuracy score:  0.9924882476108228\n"
     ]
    }
   ],
   "source": [
    "smoter = SMOTE(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = smoter.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kind Borderline-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.854806790959275\n",
      "Recall:  0.9422502870264065\n",
      "ROC score:  0.9681813832712828\n",
      "F1 score:  0.8964010703948446\n",
      "Accuracy score:  0.9922723458339104\n"
     ]
    }
   ],
   "source": [
    "borsmoter = BorderlineSMOTE(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = borsmoter.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kind Borderline-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8153299792838118\n",
      "Recall:  0.9489092996555684\n",
      "ROC score:  0.9705014796894232\n",
      "F1 score:  0.8770626624927044\n",
      "Accuracy score:  0.9905614260923408\n"
     ]
    }
   ],
   "source": [
    "borsmoter = BorderlineSMOTE(random_state=42, kind='borderline-2')\n",
    "\n",
    "train_X_resampled, train_y_resampled = borsmoter.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8433316300459888\n",
      "Recall:  0.9474167623421355\n",
      "ROC score:  0.9704710895994292\n",
      "F1 score:  0.8923492835901595\n",
      "Accuracy score:  0.9918894257012734\n"
     ]
    }
   ],
   "source": [
    "svmsmoter = SVMSMOTE(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = svmsmoter.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try KMeansSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No clusters found with sufficient samples of class True. Try lowering the cluster_balance_threshold or increasing the number of clusters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-21001b140e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkmsmoter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeansSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_balance_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_X_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmsmoter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_estim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/earthquake37/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[0;32m~/anaconda3/envs/earthquake37/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;34m\"class {}. Try lowering the cluster_balance_threshold \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                     \u001b[0;34m\"or increasing the number of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m                     \u001b[0;34m\"clusters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m                 )\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No clusters found with sufficient samples of class True. Try lowering the cluster_balance_threshold or increasing the number of clusters."
     ]
    }
   ],
   "source": [
    "kmsmoter = KMeansSMOTE(random_state=42, kmeans_estimator=16, cluster_balance_threshold=0.4)\n",
    "\n",
    "train_X_resampled, train_y_resampled = kmsmoter.fit_resample(train_X, train_y)\n",
    "\n",
    "n_estim = 100\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estim,\n",
    "                             random_state=42)\n",
    "\n",
    "rfc.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(rfc.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
